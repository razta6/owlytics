{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "from os.path import join as pjoin\n",
    "from tqdm import tqdm\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# from dtaidistance import dtw\n",
    "import pywt\n",
    "\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV, StratifiedKFold\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.neighbors import NearestNeighbors, KNeighborsClassifier \n",
    "from sklearn import preprocessing\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "import torch\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import *\n",
    "from viz import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "PLOT = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PREPROCESSING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "USE_LOW_PASS_FILTER = True\n",
    "ROLLING_WINDOW = 32\n",
    "\n",
    "DOWNSAMPLE = True\n",
    "DOWNSAMPLE_WINDOW = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder = pjoin(\"data\", \"MixedShapesRegularTrain\")\n",
    "train_fname = \"MixedShapesRegularTrain_TRAIN.tsv\"\n",
    "test_fname = \"MixedShapesRegularTrain_TEST.tsv\"\n",
    "\n",
    "train_data = pd.read_csv(pjoin(data_folder, train_fname), sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 499 entries, 0 to 498\n",
      "Columns: 1025 entries, 1 to 1.1120469\n",
      "dtypes: float64(1024), int64(1)\n",
      "memory usage: 3.9 MB\n"
     ]
    }
   ],
   "source": [
    "train_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>1.1309687</th>\n",
       "      <th>1.1204832</th>\n",
       "      <th>1.1077719</th>\n",
       "      <th>1.0424568</th>\n",
       "      <th>0.96409116</th>\n",
       "      <th>0.91385703</th>\n",
       "      <th>0.9255513</th>\n",
       "      <th>0.90369937</th>\n",
       "      <th>0.91716544</th>\n",
       "      <th>...</th>\n",
       "      <th>0.67574464</th>\n",
       "      <th>0.66714198</th>\n",
       "      <th>0.75205753</th>\n",
       "      <th>0.82026784</th>\n",
       "      <th>0.8957213</th>\n",
       "      <th>0.9829251</th>\n",
       "      <th>1.0491094</th>\n",
       "      <th>1.0931087</th>\n",
       "      <th>1.1025334</th>\n",
       "      <th>1.1120469</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.830904</td>\n",
       "      <td>0.815222</td>\n",
       "      <td>0.803198</td>\n",
       "      <td>0.742477</td>\n",
       "      <td>0.683805</td>\n",
       "      <td>0.672666</td>\n",
       "      <td>0.673233</td>\n",
       "      <td>0.679851</td>\n",
       "      <td>0.664352</td>\n",
       "      <td>...</td>\n",
       "      <td>0.545351</td>\n",
       "      <td>0.540754</td>\n",
       "      <td>0.603622</td>\n",
       "      <td>0.650685</td>\n",
       "      <td>0.708652</td>\n",
       "      <td>0.771576</td>\n",
       "      <td>0.791044</td>\n",
       "      <td>0.816584</td>\n",
       "      <td>0.819874</td>\n",
       "      <td>0.823568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.816833</td>\n",
       "      <td>0.810941</td>\n",
       "      <td>0.772436</td>\n",
       "      <td>0.734036</td>\n",
       "      <td>0.695747</td>\n",
       "      <td>0.657560</td>\n",
       "      <td>0.617705</td>\n",
       "      <td>0.579676</td>\n",
       "      <td>0.541709</td>\n",
       "      <td>...</td>\n",
       "      <td>0.677791</td>\n",
       "      <td>0.709058</td>\n",
       "      <td>0.710436</td>\n",
       "      <td>0.729174</td>\n",
       "      <td>0.743558</td>\n",
       "      <td>0.785415</td>\n",
       "      <td>0.802844</td>\n",
       "      <td>0.805283</td>\n",
       "      <td>0.807960</td>\n",
       "      <td>0.810870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1.942775</td>\n",
       "      <td>1.928545</td>\n",
       "      <td>1.903324</td>\n",
       "      <td>1.879062</td>\n",
       "      <td>1.812798</td>\n",
       "      <td>1.746591</td>\n",
       "      <td>1.675465</td>\n",
       "      <td>1.611625</td>\n",
       "      <td>1.548000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.660595</td>\n",
       "      <td>1.701224</td>\n",
       "      <td>1.748952</td>\n",
       "      <td>1.794030</td>\n",
       "      <td>1.845204</td>\n",
       "      <td>1.864267</td>\n",
       "      <td>1.860472</td>\n",
       "      <td>1.909628</td>\n",
       "      <td>1.958690</td>\n",
       "      <td>1.944351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1.873812</td>\n",
       "      <td>1.863549</td>\n",
       "      <td>1.814253</td>\n",
       "      <td>1.779266</td>\n",
       "      <td>1.766919</td>\n",
       "      <td>1.735888</td>\n",
       "      <td>1.675732</td>\n",
       "      <td>1.699785</td>\n",
       "      <td>1.720428</td>\n",
       "      <td>...</td>\n",
       "      <td>1.818965</td>\n",
       "      <td>1.854731</td>\n",
       "      <td>1.890964</td>\n",
       "      <td>1.918501</td>\n",
       "      <td>1.903307</td>\n",
       "      <td>1.910518</td>\n",
       "      <td>1.895921</td>\n",
       "      <td>1.881597</td>\n",
       "      <td>1.873381</td>\n",
       "      <td>1.898326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2.314335</td>\n",
       "      <td>2.302548</td>\n",
       "      <td>2.283370</td>\n",
       "      <td>2.246295</td>\n",
       "      <td>2.189444</td>\n",
       "      <td>2.150547</td>\n",
       "      <td>2.092030</td>\n",
       "      <td>2.038564</td>\n",
       "      <td>2.015111</td>\n",
       "      <td>...</td>\n",
       "      <td>1.970946</td>\n",
       "      <td>2.020198</td>\n",
       "      <td>2.072746</td>\n",
       "      <td>2.123032</td>\n",
       "      <td>2.172533</td>\n",
       "      <td>2.219684</td>\n",
       "      <td>2.267653</td>\n",
       "      <td>2.315809</td>\n",
       "      <td>2.317153</td>\n",
       "      <td>2.329100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 1025 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   1  1.1309687  1.1204832  1.1077719  1.0424568  0.96409116  0.91385703  \\\n",
       "0  1   0.830904   0.815222   0.803198   0.742477    0.683805    0.672666   \n",
       "1  1   0.816833   0.810941   0.772436   0.734036    0.695747    0.657560   \n",
       "2  1   1.942775   1.928545   1.903324   1.879062    1.812798    1.746591   \n",
       "3  1   1.873812   1.863549   1.814253   1.779266    1.766919    1.735888   \n",
       "4  1   2.314335   2.302548   2.283370   2.246295    2.189444    2.150547   \n",
       "\n",
       "   0.9255513  0.90369937  0.91716544  ...  0.67574464  0.66714198  0.75205753  \\\n",
       "0   0.673233    0.679851    0.664352  ...    0.545351    0.540754    0.603622   \n",
       "1   0.617705    0.579676    0.541709  ...    0.677791    0.709058    0.710436   \n",
       "2   1.675465    1.611625    1.548000  ...    1.660595    1.701224    1.748952   \n",
       "3   1.675732    1.699785    1.720428  ...    1.818965    1.854731    1.890964   \n",
       "4   2.092030    2.038564    2.015111  ...    1.970946    2.020198    2.072746   \n",
       "\n",
       "   0.82026784  0.8957213  0.9829251  1.0491094  1.0931087  1.1025334  \\\n",
       "0    0.650685   0.708652   0.771576   0.791044   0.816584   0.819874   \n",
       "1    0.729174   0.743558   0.785415   0.802844   0.805283   0.807960   \n",
       "2    1.794030   1.845204   1.864267   1.860472   1.909628   1.958690   \n",
       "3    1.918501   1.903307   1.910518   1.895921   1.881597   1.873381   \n",
       "4    2.123032   2.172533   2.219684   2.267653   2.315809   2.317153   \n",
       "\n",
       "   1.1120469  \n",
       "0   0.823568  \n",
       "1   0.810870  \n",
       "2   1.944351  \n",
       "3   1.898326  \n",
       "4   2.329100  \n",
       "\n",
       "[5 rows x 1025 columns]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: should I sort the column names?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Conclusion: the features and the labels can be seperated by the column dtype**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# splitting the dataset to its features and labels\n",
    "features = train_data.select_dtypes(include=['float64'])\n",
    "labels = train_data.select_dtypes(include=['int64'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['1'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# get the labels column name\n",
    "print(labels.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "if PLOT:\n",
    "    # get labels stats\n",
    "    plt.figure(figsize=(15,3))\n",
    "    ax = sns.countplot(y=\"1\", data=labels)\n",
    "\n",
    "    for p in ax.patches:\n",
    "        ax.annotate(f'{p.get_width()}', (p.get_width()+1, p.get_y()+0.5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Conclusion: balanced dataset**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Something with the column names doesn't make sense. maybe it should be sorted?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = features.columns.astype(\"float\")\n",
    "x = np.arange(len(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "if PLOT:\n",
    "    fig, axes = plt.subplots(1,2, figsize=(10,5))\n",
    "    axes[0].plot(x,y)\n",
    "    axes[1].plot(x,sorted(y))\n",
    "\n",
    "    axes[0].set_title(\"Original columns order\")\n",
    "    axes[1].set_title(\"Sorted columns order\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Conclusion: Maybe it should be sorted... I should read the papers refferd to in the README.md file to better understand**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualuziation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_SAMPLES_PER_CLASS = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "if PLOT:\n",
    "    samples = visualize_dataset(train_data, NUM_SAMPLES_PER_CLASS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Conclusion: looks like a clustering \\ knn algorithm will be usefull. I've noticed that some classes (e.g. 1) might have multiple sub-clusters**\n",
    "**Conclusion: looks like a low pass filtering would be usefull**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "if PLOT:\n",
    "    rolling_dataset = pd.concat([labels, features.rolling(ROLLING_WINDOW, axis=1).mean()], axis=1)\n",
    "    rolling_dataset = rolling_dataset.dropna(axis=1)\n",
    "    rolling_samples = visualize_dataset(rolling_dataset, NUM_SAMPLES_PER_CLASS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# any dupplicates?\n",
    "features.duplicated().any()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Conclusion: No**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# any missing values?\n",
    "features.isna().sum().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Conclusion: No**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(499, 993)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Low pass filtering\n",
    "if USE_LOW_PASS_FILTER:\n",
    "    features = features.rolling(ROLLING_WINDOW, axis=1).mean()\n",
    "    features = features.dropna(axis=1)\n",
    "    \n",
    "features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(499, 248)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# downsampling\n",
    "if DOWNSAMPLE:\n",
    "    features = features.rolling(DOWNSAMPLE_WINDOW, axis=1).mean()\n",
    "    features = features[features.columns[DOWNSAMPLE_WINDOW-1::DOWNSAMPLE_WINDOW]]\n",
    "    \n",
    "features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "if PLOT:\n",
    "    samples = visualize_dataset(pd.concat([labels, features], axis=1), NUM_SAMPLES_PER_CLASS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: do a kfold cross validation split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:  (array([1, 2, 3, 4, 5], dtype=int64), array([70, 70, 70, 70, 70], dtype=int64))\n",
      "Val:  (array([1, 2, 3, 4, 5], dtype=int64), array([19, 20, 20, 20, 20], dtype=int64))\n",
      "Test:  (array([1, 2, 3, 4, 5], dtype=int64), array([10, 10, 10, 10, 10], dtype=int64))\n"
     ]
    }
   ],
   "source": [
    "# splitting to train, val, test\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, labels, stratify=labels, test_size=0.1)#, random_state=1)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, stratify=y_train, test_size=0.22)#, random_state=1)\n",
    "\n",
    "\n",
    "print(\"Train: \", np.unique(y_train, return_counts = True))\n",
    "print(\"Val: \", np.unique(y_val, return_counts = True))\n",
    "print(\"Test: \", np.unique(y_test, return_counts = True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Conclusion: all sequences have the same length, therefore there is no need for special care in this aspect**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "#label encoding\n",
    "# no need for a LabelEncoder(), just substruct 1 from the labels to have it 0-based."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment #1: KNN with DTW\n",
    "\n",
    "* _"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing the DTW metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'dtaidistance'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-75-1f4d9ecb2f56>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mdtaidistance\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdtw\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;31m# from fastdtw import fastdtw\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m# from scipy.spatial.distance import euclidean\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'dtaidistance'"
     ]
    }
   ],
   "source": [
    "from dtaidistance import dtw\n",
    "# from fastdtw import fastdtw\n",
    "# from scipy.spatial.distance import euclidean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dists = [ [ None ]*len(class_names) ]*len(class_names)\n",
    "\n",
    "# for i in tqdm(range(len(class_names))):\n",
    "for i in range(len(class_names)):\n",
    "\n",
    "    for j in range(i, len(class_names)):\n",
    "        cls_x = X_train.loc[y_train[\"1\"]==class_names[i]]\n",
    "        cls_y = X_train.loc[y_train[\"1\"]==class_names[j]]\n",
    "        dists[i][j] = [dtw.distance_fast(cls_x.iloc[x].values, cls_y.iloc[y].values) for x in range(5) for y in range(5)]\n",
    "#         for x in range(5):\n",
    "#             for y in range(5):\n",
    "#                 s1 = cls_x.iloc[x].values\n",
    "#                 s2 = cls_y.iloc[y].values\n",
    "#                 print(i,j,x,y)\n",
    "#                 dists[i][j].append(dtw.distance_fast(s1, s2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(len(class_names), len(class_names), figsize=(15,10), sharey=True)\n",
    "\n",
    "for i in range(len(dists)):\n",
    "    for j in range(i, len(dists)):\n",
    "        sns.distplot(x=dists[i][j], ax=axes[i][j])\n",
    "        if i==0:\n",
    "            axes[i][j].set_title(f\"Class: {cls}\")\n",
    "    \n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dists3 = np.zeros((len(cls1),len(cls1)))\n",
    "for i in tqdm(range(len(cls2))):\n",
    "    for j in range(len(cls2)):\n",
    "        s1 = cls2.iloc[i].values\n",
    "        s2 = cls2.iloc[j].values\n",
    "        dists3[i,j] = dtw.distance_fast(s1, s2)\n",
    "# sns.distplot(dists3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(dists3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nbrs = NearestNeighbors(n_neighbors=4, algorithm='ball_tree', metric=dtw.distance_fast)\n",
    "cls = KNeighborsClassifier(n_neighbors=1, algorithm='ball_tree', metric=dtw.distance_fast)\n",
    "cls.fit(X_train, y_train[\"1\"])\n",
    "y_pred = cls.predict(X_val)\n",
    "print(classification_report(y_val, y_pred))\n",
    "print(confusion_matrix(y_val, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_val, y_pred))\n",
    "print(confusion_matrix(y_val, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cls = KNeighborsClassifier(n_neighbors=1, algorithm='ball_tree', metric=dtw.distance_fast)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cv_scores = cross_val_score(cls, \n",
    "#                             features, \n",
    "#                             labels[\"1\"], \n",
    "#                             cv=5, # integer, to specify the number of folds in a (Stratified)KFold,\n",
    "#                             scoring=\"f1_weighted\",\n",
    "#                             n_jobs=-1,\n",
    "#                            )\n",
    "# cv_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_params = {\n",
    "    \"n_neighbors\": [1,3,5,7,9],\n",
    "    \"weights\": [\"uniform\", \"distance\"],\n",
    "    \"metric\": [dtw.distance_fast, \"minkowski\"]\n",
    "}\n",
    "\n",
    "knn_gs = GridSearchCV(\n",
    "    KNeighborsClassifier(),\n",
    "    grid_params,\n",
    "    verbose=1,\n",
    "    cv=5,\n",
    "    n_jobs=-1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_gs_results = gs.fit(features, labels[\"1\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"best_score: \", knn_gs_results.best_score_)\n",
    "print(\"best_estimator_: \", knn_gs_results.best_estimator_)\n",
    "print(\"best_params_: \", knn_gs_results.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = preprocessing.MinMaxScaler()\n",
    "features_scaled = scaler.fit_transform(features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_gs_results_scaled = knn_gs.fit(features, labels[\"1\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment #2: Feature extraction with DWT + classic ML classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pywt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CWT + CNN\n",
    "# scales = np.arange(1,128)\n",
    "# waveletname = 'mexh'\n",
    "# sample = features.iloc[400]\n",
    "# time = np.arange(len(sample.index))\n",
    "# signal = sample.values\n",
    "# plot_wavelet(time, signal, scales, waveletname=waveletname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DECONSTRUCT_LEVEL = 3\n",
    "\n",
    "coeffs = pywt.wavedec(features.iloc[0], 'db2', level=DECONSTRUCT_LEVEL)\n",
    "nth_level_approx_coeffs = coeffs[0]\n",
    "nth_level_approx_coeffs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cwt_features = []\n",
    "for i, row in features.iterrows():\n",
    "    coeffs = pywt.wavedec(row, 'db2', level=DECONSTRUCT_LEVEL)\n",
    "    nth_level_approx_coeffs = coeffs[0]\n",
    "    cwt_features.append(nth_level_approx_coeffs)\n",
    "    \n",
    "cwt_features = pd.DataFrame(cwt_features, index=features.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_params = {\n",
    "    \"max_depth\": list(range(2,32,2)),\n",
    "}\n",
    "\n",
    "rf_gs = GridSearchCV(\n",
    "    RandomForestClassifier(),\n",
    "    grid_params,\n",
    "    verbose=1,\n",
    "    cv=5,\n",
    "    n_jobs=-1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_gs_results = rf_gs.fit(cwt_features, labels[\"1\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"best_score: \", rf_gs_results.best_score_)\n",
    "print(\"best_estimator_: \", rf_gs_results.best_estimator_)\n",
    "print(\"best_params_: \", rf_gs_results.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cwt_features_scaled = preprocessing.scale(cwt_features)\n",
    "# cwt_features_scaled = cwt_features - cwt_features.mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=2)\n",
    "pca.fit(cwt_features_scaled)\n",
    "X = pca.transform(cwt_features_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cls1 = X[np.where(labels[\"1\"]==1)[0]]\n",
    "cls2 = X[np.where(labels[\"1\"]==2)[0]]\n",
    "cls3 = X[np.where(labels[\"1\"]==3)[0]]\n",
    "cls4 = X[np.where(labels[\"1\"]==4)[0]]\n",
    "cls5 = X[np.where(labels[\"1\"]==5)[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(cls1[:, 0], cls1[:, 1], label=1)\n",
    "plt.scatter(cls2[:, 0], cls2[:, 1], label=2)\n",
    "plt.scatter(cls3[:, 0], cls3[:, 1], label=3)\n",
    "plt.scatter(cls4[:, 0], cls4[:, 1], label=4)\n",
    "plt.scatter(cls5[:, 0], cls5[:, 1], label=5)\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(cwt_features, labels_1[\"1\"], stratify=labels, test_size=0.2)#, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_1 = labels-1\n",
    "\n",
    "xgb_model = xgb.XGBClassifier()\n",
    "\n",
    "D_train = xgb.DMatrix(X_train, label=y_train)\n",
    "D_val = xgb.DMatrix(X_val, label=y_val)\n",
    "\n",
    "param = {\n",
    "    'eta': 0.3, \n",
    "    'max_depth': 8,  \n",
    "    'objective': 'multi:softprob',  \n",
    "    'num_class': 5} \n",
    "\n",
    "# A parameter grid for XGBoost\n",
    "params = {\n",
    "        'min_child_weight': [1, 5, 10],\n",
    "        'gamma': [0.5, 1, 1.5, 2, 5],\n",
    "        'subsample': [0.6, 0.8, 1.0],\n",
    "        'colsample_bytree': [0.6, 0.8, 1.0],\n",
    "        'max_depth': [3, 4, 5]\n",
    "        }\n",
    "\n",
    "steps = 20  # The number of training iterations\n",
    "\n",
    "model = xgb.train(param, D_train, steps)\n",
    "\n",
    "y_pred = model.predict(D_val)\n",
    "best_preds = np.asarray([np.argmax(line) for line in y_pred])\n",
    "\n",
    "print(classification_report(y_val, best_preds))\n",
    "print(confusion_matrix(y_val, best_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment #3: Deep LSTM + FC classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x15d1e948410>"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from multiprocessing import cpu_count\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "from deep_ts import LSTMClassifier\n",
    "\n",
    "from utils import *\n",
    "\n",
    "torch.manual_seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda\n"
     ]
    }
   ],
   "source": [
    "is_cuda = torch.cuda.is_available()\n",
    "\n",
    "if is_cuda:\n",
    "    device = torch.device(\"cuda\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    \n",
    "print(f\"Using {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing datasets\n",
      "Creating data loaders with batch size: 248\n"
     ]
    }
   ],
   "source": [
    "print('Preparing datasets')\n",
    "trn_ds, val_ds, enc = create_datasets(features, labels[\"1\"])\n",
    "\n",
    "bs = features.shape[1]\n",
    "print(f'Creating data loaders with batch size: {bs}')\n",
    "trn_dl, val_dl = create_loaders(trn_ds, val_ds, bs, jobs=cpu_count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "train() takes from 1 to 2 positional arguments but 10 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-172-a554cb8af5c1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[0msched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCyclicLR\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mopt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcosine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt_max\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0miterations_per_epoch\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0meta_min\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlr\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrn_dl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval_dl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_epochs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msched\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mopt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpatience\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: train() takes from 1 to 2 positional arguments but 10 were given"
     ]
    }
   ],
   "source": [
    "input_dim = features.shape[1]\n",
    "hidden_dim = 128\n",
    "layer_dim = 1\n",
    "output_dim = 5\n",
    "\n",
    "n_epochs = 1000\n",
    "patience = 100\n",
    "lr = 0.0005\n",
    "iterations_per_epoch = len(trn_dl)\n",
    "\n",
    "model = LSTMClassifier(input_dim, hidden_dim, layer_dim, output_dim)\n",
    "model = model.to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "opt = torch.optim.RMSprop(model.parameters(), lr=lr)\n",
    "sched = CyclicLR(opt, cosine(t_max=iterations_per_epoch * 2, eta_min=lr/100))\n",
    "\n",
    "model.run(model, trn_dl, val_dl, n_epochs, sched, opt, criterion, device, patience)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training is finished! Restoring the best model weights\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('The training is finished! Restoring the best model weights')\n",
    "\n",
    "model.load_state_dict(torch.load('best.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LSTMClassifier(\n",
       "  (rnn): LSTM(248, 128, batch_first=True)\n",
       "  (fc): Linear(in_features=128, out_features=5, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = preds\n",
    "a = [a for i in range(10)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([4, 4, 0, 4, 2, 2, 1, 0, 3, 3, 3, 3, 3, 1, 4, 3, 3, 3, 4, 1, 1, 1, 2, 3,\n",
       "        1, 1, 3, 0, 4, 0, 4, 0, 1, 2, 1, 4], device='cuda:0')"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.80      0.73         5\n",
      "           1       0.89      0.89      0.89         9\n",
      "           2       0.50      0.75      0.60         4\n",
      "           3       1.00      0.80      0.89        10\n",
      "           4       1.00      0.88      0.93         8\n",
      "\n",
      "    accuracy                           0.83        36\n",
      "   macro avg       0.81      0.82      0.81        36\n",
      "weighted avg       0.87      0.83      0.84        36\n",
      "\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
